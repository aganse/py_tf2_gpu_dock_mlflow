
    # Or when datasets contain differently-sized images (eg the malaria example),
    # those can't be batched together as above, so here's an approach that makes
    # batches of one; however note this is really inefficient...
    # reference:
    # https://stackoverflow.com/questions/51983716/tensorflow-input-dataset-with-varying-size-images
    # and useful summary of this issue:
    # https://stats.stackexchange.com/questions/388859/is-it-possible-to-give-variable-sized-images-as-input-to-a-convolutional-neural
    #
    # dataset = tf.data.Dataset.from_generator(
    #     generator=gen_callable(batch_size, samples, train),
    #     output_types=(tf.uint8, tf.uint8),
    #     output_shapes=(tf.TensorShape([1, None, None, 3]), tf.TensorShape([1, None]))
    # )
    # dataset = dataset.repeat()
    # iterator = dataset.make_one_shot_iterator()
    # return iterator.get_next()

